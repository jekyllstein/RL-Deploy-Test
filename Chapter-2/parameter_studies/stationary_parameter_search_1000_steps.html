<html>
<head><meta charset="utf-8" /></head>
<body>
<div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script>
    <script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
</script>
<script src="https://cdn.plot.ly/plotly-2.3.0.min.js"></script>

    <div
        id=ae0076dd-1409-41bd-85e2-c949323300d1
        class="plotly-graph-div"
        style="height:500; width:700;">
    </div>
    <script type="text/javascript">
        
        window.PLOTLYENV = window.PLOTLYENV || {}
        
        if (document.getElementById('ae0076dd-1409-41bd-85e2-c949323300d1')) {
    Plotly.newPlot(
        'ae0076dd-1409-41bd-85e2-c949323300d1',
        [{"mode":"markers","y":[1.5606697,1.5615423,1.5615923,1.561872,1.5611156,1.5606337,1.560452,1.56216,1.5618703,1.5614648,1.5625932,1.56217,1.561934,1.5615739,1.5626066,1.5608041,1.5607665,1.5611207,1.5607442,1.5606754,1.5613835,1.561022,1.5613929,1.5613596,1.5614015,1.5614387,1.5613601,1.5616033,1.5617702,1.5614225,1.561561,1.5615624,1.5615611,1.5615613,1.5615621,1.5615621,1.5615618,1.5615617,1.5615622,1.5615608],"type":"scatter","name":"ideal","hovertemplate":"ideal reward = %{y:.3g}<extra></extra>","x":[0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5,0.03125,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0,16.0,32.0]},{"line":{"color":"#1170AA"},"y":[1.1664306,1.2554171,1.3213457,1.3447006,1.3031064,1.1308689,0.7611748],"type":"scatter","name":"$\\epsilon\\text{-greedy }$","legendgroup":"#1170AA","hovertemplate":["ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.69530475","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.8927628","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.0568079","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.1734706","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.1912996","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.98867196","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.50357175"],"x":[0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5]},{"showlegend":false,"line":{"color":"#1170AA","dash":"dot","width":5},"y":[0.69530475,0.8927628,1.0568079,1.1734706,1.1912996,0.98867196,0.50357175],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#1170AA","hovertemplate":["ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.69530475","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.8927628","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.0568079","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.1734706","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.1912996","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.98867196","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.50357175"],"x":[0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5]},{"line":{"color":"#FC7D0B"},"y":[1.1231031,1.3104228,1.4033448,1.431942,1.3786062,1.2487555,1.0575929,0.78726393],"type":"scatter","name":"$\\text{gradient bandit }$","legendgroup":"#FC7D0B","hovertemplate":["α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.0438167","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.2329657","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.300873","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.2779505","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.0910664","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.80923915","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.45116156","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.0024624467"],"x":[0.03125,0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"showlegend":false,"line":{"color":"#FC7D0B","dash":"dot","width":5},"y":[1.0438167,1.2329657,1.300873,1.2779505,1.0910664,0.80923915,0.45116156,0.0024624467],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#FC7D0B","hovertemplate":["α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.0438167","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.2329657","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.300873","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.2779505","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.0910664","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.80923915","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.45116156","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.0024624467"],"x":[0.03125,0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"line":{"color":"#A3ACB9"},"y":[1.4439043,1.4572744,1.4735932,1.5040085,1.501739,1.413932,1.1871676],"type":"scatter","name":"UCB","legendgroup":"#A3ACB9","hovertemplate":["c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.2216153","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.2601187","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.3003931","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.400396","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.4669175","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.3798985","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.136007"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"showlegend":false,"line":{"color":"#A3ACB9","dash":"dot","width":5},"y":[1.2216153,1.2601187,1.3003931,1.400396,1.4669175,1.3798985,1.136007],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#A3ACB9","hovertemplate":["c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.2216153","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.2601187","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.3003931","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.400396","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.4669175","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.3798985","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.136007"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"line":{"color":"#57606C"},"y":[1.2485651,1.2797813,1.3318669,1.4163418,1.4765378,1.4367546,1.3500968,1.2582238],"type":"scatter","name":"$\\text{greedy optimistic initialization } \\alpha = 0.1$","legendgroup":"#57606C","hovertemplate":["Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.8105154","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.8645263","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.9648422","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.1461949","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3567201","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3812231","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3103057","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.2158625"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0]},{"showlegend":false,"line":{"color":"#57606C","dash":"dot","width":5},"y":[0.8105154,0.8645263,0.9648422,1.1461949,1.3567201,1.3812231,1.3103057,1.2158625],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#57606C","hovertemplate":["Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.8105154","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.8645263","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.9648422","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.1461949","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3567201","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3812231","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3103057","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.2158625"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0]},{"line":{"color":"#5FA2CE"},"y":[1.5039141,1.5039136,1.5039134,1.5039146,1.5039147,1.503914,1.5039148,1.5039136,1.5039128,1.5039136],"type":"scatter","name":"$\\text{Optimal Distribution}$","legendgroup":"#5FA2CE","hovertemplate":["Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.440683","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406825","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406823","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406835","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406836","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406829","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406837","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406825","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406817","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406825"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0,16.0,32.0]},{"showlegend":false,"line":{"color":"#5FA2CE","dash":"dot","width":5},"y":[1.440683,1.4406825,1.4406823,1.4406835,1.4406836,1.4406829,1.4406837,1.4406825,1.4406817,1.4406825],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#5FA2CE","hovertemplate":["Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.440683","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406825","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406823","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406835","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406836","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406829","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406837","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406825","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406817","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406825"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0,16.0,32.0]}],
        {"xaxis":{"type":"log","tickvals":[0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0,16.0,32.0],"title":"Method Parameter (see hovertext)","ticktext":["$\\frac{1}{128}$","$\\frac{1}{64}$","$\\frac{1}{32}$","$\\frac{1}{16}$","$\\frac{1}{8}$","$\\frac{1}{4}$","$\\frac{1}{2}$","$1$","$2$","$4$","$8$","$16$","$32$"]},"template":{"layout":{"coloraxis":{"colorbar":{"ticks":"","outlinewidth":0}},"xaxis":{"gridcolor":"white","zerolinewidth":2,"title":{"standoff":15},"ticks":"","zerolinecolor":"white","automargin":true,"linecolor":"white"},"hovermode":"closest","paper_bgcolor":"white","geo":{"showlakes":true,"showland":true,"landcolor":"#E5ECF6","bgcolor":"white","subunitcolor":"white","lakecolor":"white"},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"yaxis":{"gridcolor":"white","zerolinewidth":2,"title":{"standoff":15},"ticks":"","zerolinecolor":"white","automargin":true,"linecolor":"white"},"shapedefaults":{"line":{"color":"#2a3f5f"}},"hoverlabel":{"align":"left"},"mapbox":{"style":"light"},"polar":{"angularaxis":{"gridcolor":"white","ticks":"","linecolor":"white"},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","ticks":"","linecolor":"white"}},"autotypenumbers":"strict","font":{"color":"#2a3f5f"},"ternary":{"baxis":{"gridcolor":"white","ticks":"","linecolor":"white"},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","ticks":"","linecolor":"white"},"aaxis":{"gridcolor":"white","ticks":"","linecolor":"white"}},"annotationdefaults":{"arrowhead":0,"arrowwidth":1,"arrowcolor":"#2a3f5f"},"plot_bgcolor":"#E5ECF6","title":{"x":0.05},"scene":{"xaxis":{"gridcolor":"white","gridwidth":2,"backgroundcolor":"#E5ECF6","ticks":"","showbackground":true,"zerolinecolor":"white","linecolor":"white"},"zaxis":{"gridcolor":"white","gridwidth":2,"backgroundcolor":"#E5ECF6","ticks":"","showbackground":true,"zerolinecolor":"white","linecolor":"white"},"yaxis":{"gridcolor":"white","gridwidth":2,"backgroundcolor":"#E5ECF6","ticks":"","showbackground":true,"zerolinecolor":"white","linecolor":"white"}},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"]},"data":{"barpolar":[{"type":"barpolar","marker":{"line":{"color":"#E5ECF6","width":0.5}}}],"carpet":[{"aaxis":{"gridcolor":"white","endlinecolor":"#2a3f5f","minorgridcolor":"white","startlinecolor":"#2a3f5f","linecolor":"white"},"type":"carpet","baxis":{"gridcolor":"white","endlinecolor":"#2a3f5f","minorgridcolor":"white","startlinecolor":"#2a3f5f","linecolor":"white"}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"parcoords":[{"line":{"colorbar":{"ticks":"","outlinewidth":0}},"type":"parcoords"}],"scatter":[{"type":"scatter","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"histogram2dcontour":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"histogram2dcontour","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contour":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"contour","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"mesh3d":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"mesh3d"}],"surface":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"surface","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"histogram":[{"type":"histogram","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"pie":[{"type":"pie","automargin":true}],"choropleth":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"choropleth"}],"heatmapgl":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"heatmapgl","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"bar":[{"type":"bar","error_y":{"color":"#2a3f5f"},"error_x":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5}}}],"heatmap":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"heatmap","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"contourcarpet"}],"table":[{"type":"table","header":{"line":{"color":"white"},"fill":{"color":"#C8D4E3"}},"cells":{"line":{"color":"white"},"fill":{"color":"#EBF0F8"}}}],"scatter3d":[{"line":{"colorbar":{"ticks":"","outlinewidth":0}},"type":"scatter3d","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"histogram2d":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"histogram2d","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}]}},"legend":{"y":-0.2,"orientation":"h","x":-0.1},"margin":{"l":50,"b":50,"r":50,"t":60},"yaxis":{"title":"Average Reward over first 1000 steps"},"height":500,"width":700},
        {"editable":false,"responsive":true,"staticPlot":false,"scrollZoom":true},
    )
}

        
    </script>
</div>

</body>
</html>